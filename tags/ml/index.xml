<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML on Avatar&#39;s Blog</title>
    <link>http://blog.ryune.top/tags/ml/</link>
    <description>Recent content in ML on Avatar&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 15 Aug 2019 15:01:39 +0800</lastBuildDate>
    
	<atom:link href="http://blog.ryune.top/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ML: 个人浅析</title>
      <link>http://blog.ryune.top/posts/ml-wann/</link>
      <pubDate>Thu, 15 Aug 2019 15:01:39 +0800</pubDate>
      
      <guid>http://blog.ryune.top/posts/ml-wann/</guid>
      <description>ML 本质 关键词: 数据模型
WANN 权重不可知神经网络
  只靠神经网络架构搜索出的网络，不训练，不调参，就能直接执行任务 它在MNIST数字分类任务上，未经训练和权重调整，就达到了92%的准确率，和训练后的线性分类器表现相当 除了监督学习，WANN还能胜任许多强化学习任务   强化学习 WANN处理了3种强化学习任务。给每一组神经元，共享同一个权重。 * Cart-Pole Swing-Up * Bipedal Waker-v2 * CarRacing-v0
实现原理 目的: 权重对网络的影响最小化
步骤: 1. 权重共享, 让权重值减少到1个 2. 最小神经网络拓扑群开始 3. 通过分配不同的共享权重根据性能与复杂度进行排序 4. 迭代 &amp;amp; 竞争
关键词: 调不出明天 神经网络架构
results: {&#39;mean_fit_time&#39;: array([1.13031559, 1.14794617, 1.15004916, 1.11991968, 1.1085814 , 1.12418618, 1.10943542, 1.10974827, 1.47658706, 1.4929059 , 1.49251971, 1.51477184, 1.49152155, 1.49738503, 1.51293812, 1.54513607, 2.0294167 , 2.08700633, 2.23434725, 2.01368504, 2.06274705, 2.18829951, 1.95969872, 1.</description>
    </item>
    
  </channel>
</rss>